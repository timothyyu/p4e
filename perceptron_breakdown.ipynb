{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/6-steps-to-write-any-machine-learning-algorithm-from-scratch-perceptron-case-study-335f638a70f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from past.builtins import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron function\n",
    "def perceptron(x, y, z, eta, t):\n",
    "    '''\n",
    "    Input Parameters:\n",
    "        x: data set of input features\n",
    "        y: actual outputs\n",
    "        z: activation function threshold\n",
    "        eta: learning rate\n",
    "        t: number of iterations\n",
    "    '''\n",
    "    \n",
    "    # initializing the weights\n",
    "    w = np.zeros(len(x[0]))      \n",
    "    n = 0                        \n",
    "    \n",
    "    # initializing additional parameters to compute sum-of-squared errors\n",
    "    yhat_vec = np.ones(len(y))     # vector for predictions\n",
    "    errors = np.ones(len(y))       # vector for errors (actual - predictions)\n",
    "    J = []                         # vector for the SSE cost function\n",
    "    \n",
    "    while n < t: \n",
    "        for i in xrange(0, len(x)): # dot product f = np.dot(x[i], w) # activation function if f >= z:                               \n",
    "                yhat = 1.                               \n",
    "        else:                                   \n",
    "            yhat = 0.1\n",
    "        yhat_vec[i] = yhat\n",
    "\n",
    "        # updating the weights\n",
    "        for j in xrange(0, len(w)):             \n",
    "            w[j] = w[j] + eta*(y[i]-yhat)*x[i][j]\n",
    "                \n",
    "        n += 1\n",
    "        # computing the sum-of-squared errors\n",
    "        for i in xrange(0,len(y)):     \n",
    "            errors[i] = (y[i]-yhat_vec[i])**2\n",
    "            J.append(0.5*np.sum(errors))\n",
    "        \n",
    "    return w, J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     x0  x1  x2\n",
    "x = [[1., 0., 0.],\n",
    "     [1., 0., 1.],\n",
    "     [1., 1., 0.],\n",
    "     [1., 1., 1.]]\n",
    "\n",
    "y =[1.,\n",
    "    1.,\n",
    "    1.,\n",
    "    0.]\n",
    "\n",
    "z = 0.00\n",
    "eta = 0.1\n",
    "t = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights are:\n",
      "[-0.5 -0.5 -0.5]\n",
      "The errors are:\n",
      "[1.5, 1.0, 0.5, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001, 0.005000000000000001]\n"
     ]
    }
   ],
   "source": [
    "w,J = perceptron(x, y, z, eta, t)\n",
    "print (\"The weights are:\")\n",
    "print (w)\n",
    "print (\"The errors are:\")\n",
    "print (J)\n",
    "\n",
    "# Out:\n",
    "# The weights are:\n",
    "# [ 0.2 -0.2 -0.1]\n",
    "# The errors are:\n",
    "# [0.5, 1.5, 1.5, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
